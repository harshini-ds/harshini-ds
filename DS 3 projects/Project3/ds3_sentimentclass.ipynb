{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Hotel Reviews: sentiment classification with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in review table from yelp database\n",
    "import pandas as pd\n",
    "reviews_df = pd.read_sql_table(\"review\", \"sqlite:///yelpHotelData.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query using SQL if you'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sql extension\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database (or creatge new one if none exists)\n",
    "%sql sqlite:///yelpHotelData.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM review\n",
    "LIMIT 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensions\n",
    "print(f\"Corpus contains {reviews_df.shape[0]} documents (i.e. individual reviews)\")\n",
    "print(f\"Corpus contains {reviews_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check out data and columns\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get smaller sample of the data to speed up computation later\n",
    "small_df = reviews_df.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are useful reviews also cool?\n",
    "(ggplot(small_df, aes(x=\"usefulCount\",\n",
    "                       y=\"coolCount\")) +\n",
    "geom_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are useful reviews also funny?\n",
    "(ggplot(small_df, aes(x=\"usefulCount\",\n",
    "                       y=\"funnyCount\")) +\n",
    "geom_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get smaller sample of the data to speed up computation later\n",
    "small_df = reviews_df.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove neutral ratings\n",
    "small_df = small_df[small_df[\"rating\"] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   count\n",
       "rating       \n",
       "1        4789\n",
       "2        9101\n",
       "4       38561\n",
       "5       25058"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make sure 3 rating has been removed\n",
    "pd.crosstab(small_df[\"rating\"], columns=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create binary label 1=positive rating, 0 negative\n",
    "import numpy as np\n",
    "small_df[\"pos_rev\"] = np.where(small_df[\"rating\"] > 4, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_rev</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       count\n",
       "pos_rev          \n",
       "0        0.676709\n",
       "1        0.323291"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get percent pos and neg: 32% postiive\n",
    "pd.crosstab(small_df[\"pos_rev\"], columns=\"count\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create X (features) and Y (target)\n",
    "sentiment_label = small_df[[\"pos_rev\"]]\n",
    "sentiment_features = small_df[[\"reviewContent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_features,\n",
    "                                                    sentiment_label,\n",
    "                                                   test_size = 0.2,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import and instantiate vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize training text\n",
    "reviews_xtrain = vec.fit_transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize test text\n",
    "reviews_xtest = vec.transform(X_test[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import cross_val_score and logistic regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use 5 fold cross validation with logistic regression\n",
    "scores = cross_val_score(LogisticRegression(), \n",
    "                         reviews_xtrain,\n",
    "                        y_train,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averge cv accuracy: 0.736142804470526\n"
     ]
    }
   ],
   "source": [
    "print(f\"Averge cv accuracy: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter tuning with GridSearchCV and regularization parameter C\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set parameters\n",
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cross-validation score: 0.7490122492605555\n",
      "Optimal parameters:  {'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Instantiaite grid object\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "\n",
    "# Fit\n",
    "grid.fit(reviews_xtrain, y_train)\n",
    "print(f\"Optimal cross-validation score: {grid.best_score_}\")\n",
    "print(f\"Optimal parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#reviews_xtest = vec.transform(X_test[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.7489356212101664\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "print(f\"Score on test set: {grid.score(reviews_xtest, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Naive Bayes: Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import cross_val_score and naive bayes\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate class\n",
    "gb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(MultinomialNB(), \n",
    "                         reviews_xtrain,\n",
    "                        y_train,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averge cv accuracy: 0.7270791883457021\n"
     ]
    }
   ],
   "source": [
    "print(f\"Averge cv accuracy: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Naive Bayes: BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import cross_val_score and naive bayes bernoulli\n",
    "# differs from multinomial NB’s rule in that it explicitly penalizes\n",
    "#  the non-occurrence of a feature  that is an indicator for class , \n",
    "# where the multinomial variant would simply ignore a non-occurring feature.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(BernoulliNB(), \n",
    "                         reviews_xtrain,\n",
    "                        y_train,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7354459 , 0.7331882 , 0.73776308, 0.72752197, 0.73308604])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averge cv accuracy: 0.7334010380761022\n"
     ]
    }
   ],
   "source": [
    "print(f\"Averge cv accuracy: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing LR, MN, BN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lr = cross_val_score(LogisticRegression(), \n",
    "                         reviews_xtrain,\n",
    "                        y_train,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mn = cross_val_score(MultinomialNB(), \n",
    "                         reviews_xtrain,\n",
    "                        y_train,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_bn = cross_val_score(BernoulliNB(), \n",
    "                         reviews_xtrain,\n",
    "                        y_train,\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame({\n",
    "    \"model\": [\"LogReg\", \"MultiNB\", \"BernNB\"],\n",
    "    \"mean_score\": [np.mean(scores_lr),\n",
    "    np.mean(scores_mn),\n",
    "    np.mean(scores_bn)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.736143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultiNB</td>\n",
       "      <td>0.727079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernNB</td>\n",
       "      <td>0.733401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  mean_score\n",
       "0   LogReg    0.736143\n",
       "1  MultiNB    0.727079\n",
       "2   BernNB    0.733401"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='model', ylabel='mean_score'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"model\",\n",
    "           y=\"mean_score\",\n",
    "           data=scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate confusion matrix with logreg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "fitted_mod = lr.fit(reviews_xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generat predictions with test set\n",
    "y_pred = fitted_mod.predict(reviews_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8953 1493]\n",
      " [2575 2481]]\n"
     ]
    }
   ],
   "source": [
    "# Assess using relevant metrics: confusion matrix   true/pred   #  no/no |  no/yes\n",
    "from sklearn.metrics import confusion_matrix                        # yes/no |  yes/yes\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.81     10446\n",
      "           1       0.62      0.49      0.55      5056\n",
      "\n",
      "    accuracy                           0.74     15502\n",
      "   macro avg       0.70      0.67      0.68     15502\n",
      "weighted avg       0.73      0.74      0.73     15502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision probably more important here \n",
    "# (We probably want to focus on negative reviews to improve services so don't want to classify a negative review as positive)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving model by adjusting CountVectorizer parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize training text\n",
    "reviews_xtrain = CountVectorizer().fit_transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 83569\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {reviews_xtrain.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize training text, set min_df to 5\n",
    "reviews_xtrain = CountVectorizer(min_df=5).fit_transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features, excluding words that appear in less than 5 documents: 25988\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features, excluding words that appear in less than 5 documents: {reviews_xtrain.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cross-validation score: 0.7488993629415963\n"
     ]
    }
   ],
   "source": [
    "### Testing with smaller feature space, improvement?\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(reviews_xtrain, y_train)\n",
    "print(f\"Optimal cross-validation score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as esw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words in list: 318\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of stop words in list: {len(esw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples of stopwords:\n",
      "every\n",
      "sincere\n",
      "what\n",
      "will\n",
      "became\n",
      "always\n",
      "other\n",
      "co\n",
      "amongst\n",
      "someone\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(\"Some examples of stopwords:\")\n",
    "for i,words in enumerate(random.sample(esw, 10)):\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stopwords\n",
    "reviews_xtrain = CountVectorizer(min_df=5,\n",
    "                                stop_words=esw).fit_transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features, excluding words that appear in less than 5 documents and stopwords: 25686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Number of features, excluding words that appear in less than 5 documents and stopwords: {reviews_xtrain.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 302 fewer words than last vectorization\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are now {25885-25583} fewer words than last vectorization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords in nltk and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stopwords from nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words in list: 179\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of stop words in list: {len(nltk_sw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stopwrods from spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as spacy_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words in list: 326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of stop words in list: {len(spacy_sw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in spacy but not in nltk: {'whenever', \"'re\", 'could', 'already', 'seems', 'regarding', 'even', 'next', 'throughout', 'see', 'whereupon', 'also', 'either', 'side', 'forty', 'ca', 'whence', 'sometimes', 'hundred', 'top', \"'m\", 'along', 'onto', 'get', 'may', 'via', 'nothing', 'within', 'done', 'noone', '‘ll', '‘ve', 'almost', 'nowhere', 'whatever', 'another', 'somehow', 'cannot', 'front', 'ever', 'moreover', 'unless', 'without', 'eleven', 'really', 'give', 'full', '‘m', 'name', 'yet', 'across', 'anyhow', 'thereby', 'take', 'however', 'alone', 'became', 'formerly', 'call', 'becoming', '’m', 'beside', 'something', 'fifteen', 'enough', 'become', '‘d', \"'ve\", 'n‘t', 'put', 'indeed', 'sometime', 'eight', 'twelve', 'using', 'would', 'always', 'whoever', 'hence', 'still', 'less', 'behind', 'whereas', 'show', '‘re', 'amongst', 'though', 'thereafter', 'must', 'neither', '’d', 'mostly', 'upon', 'together', 'thru', 'say', 'whither', '’s', 'often', 'whether', 'although', 'first', 'wherever', 'various', 'everyone', 'namely', 'thence', '’ve', 'whereby', 'much', 'around', 'everywhere', 'n’t', 'six', 'thereupon', 'serious', 'therefore', 'towards', 'hereby', \"'d\", 'many', 'ten', 'besides', 'rather', 'whose', 'one', 'elsewhere', '‘s', 'among', 'fifty', 'nevertheless', '’re', 'whole', 'beforehand', 'empty', 'seeming', 'move', 'hereafter', 'every', 'everything', 'please', 'else', 'per', 'well', 'due', 'perhaps', 'sixty', 'otherwise', 'afterwards', 'part', 'meanwhile', 'seemed', \"n't\", 'former', 'wherein', 'since', 'seem', 'go', 'bottom', 'might', 'least', 'none', 'five', 'never', 'several', 'nobody', 'herein', 'back', 'except', 'two', 'beyond', '’ll', 'toward', 'anyway', 'three', 'whereafter', 'latterly', 'hereupon', 'third', 'thus', 'others', 'nine', 'therein', 'keep', \"'ll\", 'somewhere', 'last', 'latter', \"'s\", 'make', 'made', 'becomes', 'mine', 'twenty', 'us', 'anywhere', 'anything', 'amount', 'used', 'four', 'someone', 'quite', 'anyone'}\n"
     ]
    }
   ],
   "source": [
    "#### Comparing stopword lists\n",
    "print(f\"Words in spacy but not in nltk: {spacy_sw.difference(set(nltk_sw))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in spacy but not in sklearn: {'’m', 'does', '’ve', \"'re\", 'regarding', 'n’t', '‘d', 'ca', \"'d\", 'n‘t', \"'ve\", '’ll', \"'m\", '‘s', 'using', '’re', '‘ll', '‘ve', 'did', 'doing', '‘re', \"'ll\", '’d', 'say', \"'s\", 'make', 'unless', 'just', '’s', 'really', '‘m', 'used', 'various', \"n't\", 'quite'}\n"
     ]
    }
   ],
   "source": [
    "#### Comparing stopword lists\n",
    "print(f\"Words in spacy but not in sklearn: {spacy_sw.difference(esw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_sw = set.union(set(nltk_sw), spacy_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy and nltk stopword list combined has 382 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"spacy and nltk stopword list combined has {len(both_sw)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use both_sw to remove stopwords and vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize training text, set min_df to 5\n",
    "reviews_xtrain = CountVectorizer(min_df=5,\n",
    "                                stop_words=both_sw).fit_transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features, excluding words that appear in less than 5 documents and stopwords from nltk and spacy: 25676\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features, excluding words that appear in less than 5 documents and stopwords from nltk and spacy: {reviews_xtrain.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cross-validation score: 0.7420130387027457\n"
     ]
    }
   ],
   "source": [
    "### Testing with smaller feature space, improvement?\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(reviews_xtrain, y_train)\n",
    "print(f\"Optimal cross-validation score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add more stopwords to list\n",
    "# both_sw.add(\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use max_df to exlude frequent words\n",
    "    # max_df=INT remove words that occur in more than INT documents\n",
    "    # max_df=FLOAT remove words that appear in more than FLOAT % of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize training text\n",
    "reviews_xtrain = CountVectorizer().fit_transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 83569\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {reviews_xtrain.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize training text, set max_df to 50%, remove words that appear in more than 70% of documents\n",
    "reviews_xtrain = CountVectorizer(max_df=0.50).fit_transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features, excluding words that appear in less than 5 documents: 83553\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features, excluding words that appear in less than 5 documents: {reviews_xtrain.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "my_pipeline = make_pipeline(TfidfVectorizer(min_df=5),\n",
    "                           LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter grid\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid\n",
    "grid = GridSearchCV(my_pipeline, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(min_df=5)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass pre-vectorized training text, can take a few minutes\n",
    "grid.fit(X_train[\"reviewContent\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cv score 0.7565113232684169\n"
     ]
    }
   ],
   "source": [
    "# Improvement?\n",
    "print(f\"Optimal cv score {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine tf-idf scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize training text data\n",
    "X_train = vec.transform(X_train[\"reviewContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max values for each of the features in corpus\n",
    "max_val = X_train.max(axis=0).toarray().ravel()\n",
    "sorted_tfidf = max_val.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "names = np.array(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Least important (lowest tf-idf): {names[sorted_tfidf[:20]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Most important (highest tf-idf): {names[sorted_tfidf[-20:]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words with more than one word (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             \"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=2)\n",
    "grid.fit(X_train[\"reviewContent\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Optimal CV score: {grid.best_score_}\")\n",
    "print(f\"Optimal parameter {grid.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
